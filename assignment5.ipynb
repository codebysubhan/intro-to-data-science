{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d8286fe-1a56-465a-b9ed-b3c981c4e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8748179-e372-4514-b675-ab24f0960cf9",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "- Load the given datasets into Pandas DataFrames. Inspect the datasets and perform the following:\n",
    "- Display the first few rows of each dataset.\n",
    "- Show the total number of rows and columns.\n",
    "- Check for missing values in each dataset and handle them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eedba17a-384f-47c3-b4f0-e95686628156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  Age         City\n",
      "0           1   22     New York\n",
      "1           2   23  Los Angeles\n",
      "2           3   24      Chicago\n",
      "3           4   25      Houston\n",
      "4           5   26      Phoenix\n",
      "5           6   27     New York\n",
      "6           7   28  Los Angeles\n",
      "7           8   29      Chicago\n",
      "8           9   30      Houston\n",
      "9          10   31      Phoenix\n",
      "   SaleID  CustomerID     Product  Amount\n",
      "0     101           1      Laptop     200\n",
      "1     102           2  Smartphone     500\n",
      "2     103           3      Tablet     800\n",
      "3     104           4  Headphones    1100\n",
      "4     105           5     Monitor    1400\n",
      "5     106           6      Laptop     200\n",
      "6     107           7  Smartphone     500\n",
      "7     108           8      Tablet     800\n",
      "8     109           9  Headphones    1100\n",
      "9     110          10     Monitor    1400\n"
     ]
    }
   ],
   "source": [
    "data_cus = pd.read_csv(\"customers.csv\")\n",
    "data_sal = pd.read_csv(\"sales.csv\")\n",
    "print(data_cus.head(10))\n",
    "print(data_sal.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9188d25-c784-442f-bf73-da3e33661475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of customers.csv is:  (100, 3)\n",
      "Shape of sales.csv is:  (400, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of customers.csv is: \", data_cus.shape)\n",
    "print(\"Shape of sales.csv is: \", data_sal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5978d089-f2e1-451f-8c01-650813681148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows, columns in customers.csv are:  100 3\n",
      "Total rows, columns in sales.csv are:  400 4\n",
      "Total missing values in customers.csv are:  0\n",
      "Total missing values in sales.csv are:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total rows, columns in customers.csv are: \", data_cus.shape[0], data_cus.shape[1])\n",
    "print(\"Total rows, columns in sales.csv are: \", data_sal.shape[0], data_sal.shape[1])\n",
    "print(\"Total missing values in customers.csv are: \", data_cus.isnull().sum().sum())\n",
    "print(\"Total missing values in sales.csv are: \", data_sal.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1340035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that missing values are 0 in both dataframes. However, for the sake of this assignment if we want to handle missing values\n",
    "# we can use the following two methods.\n",
    "# No 1 : we can change the missing value with some other value that we want like: \"Unknown\"\n",
    "data_cus.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# No 2 : we can delete the rows with the null values in them.\n",
    "data_sal.dropna(inplace=True)\n",
    "\n",
    "# The inplace attribute changes the dataframe without having the requirement of creating new dataframe explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59416ae",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "- Using the customers.csv file, convert its data into a Python dictionary. Use the dictionary to filter customers from a specific city. Repeat the operation using a DataFrame and compare the efficiency of both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b89c4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CustomerID': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100],\n",
       " 'Age': [22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31],\n",
       " 'City': ['New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix',\n",
       "  'New York',\n",
       "  'Los Angeles',\n",
       "  'Chicago',\n",
       "  'Houston',\n",
       "  'Phoenix']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# customers.csv dataframe is data_cus\n",
    "# dict_cus = dict(data_cus)\n",
    "# or we can use\n",
    "dict_cus = data_cus.to_dict(orient=\"list\")\n",
    "dict_cus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615acd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered customers using dictionary: [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96]\n",
      "Time taken using dictionary: 0.0\n"
     ]
    }
   ],
   "source": [
    "# now we will filter using 2 different methods below:\n",
    "\n",
    "# City to filter\n",
    "city_to_filter = \"New York\"\n",
    "\n",
    "# Filter using dictionary\n",
    "start_dict = time.time()\n",
    "filtered_customers_dict = [\n",
    "    cust_id for city, cust_id in zip(data_cus[\"City\"], data_cus[\"CustomerID\"]) if city == city_to_filter\n",
    "]\n",
    "end_dict = time.time()\n",
    "print(\"Filtered customers using dictionary:\", filtered_customers_dict)\n",
    "print(\"Time taken using dictionary:\", end_dict - start_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af850847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered customers using DataFrame: [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96]\n",
      "Time taken using DataFrame: 0.015897512435913086\n"
     ]
    }
   ],
   "source": [
    "# using dataframe to filter:\n",
    "\n",
    "# Filter using DataFrame\n",
    "start_df = time.time()\n",
    "filtered_customers_df = data_cus.loc[data_cus[\"City\"] == city_to_filter, \"CustomerID\"].tolist()\n",
    "end_df = time.time()\n",
    "print(\"Filtered customers using DataFrame:\", filtered_customers_df)\n",
    "print(\"Time taken using DataFrame:\", end_df - start_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97dea64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken using dictionary: 0.0\n",
      "Time taken using DataFrame: 0.015897512435913086\n"
     ]
    }
   ],
   "source": [
    "# finding the difference:\n",
    "print(\"Time taken using dictionary:\", end_dict - start_dict)\n",
    "print(\"Time taken using DataFrame:\", end_df - start_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea2551",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "- Identify duplicate rows, if any, in the datasets. Remove these duplicates to ensure clean data.\n",
    "- After cleaning, verify that there are no duplicates left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11963a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in Customers DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: [CustomerID, Age, City]\n",
      "Index: []\n",
      "\n",
      "Duplicate rows in Orders DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: [SaleID, CustomerID, Product, Amount]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in customers dataset\n",
    "print(\"Duplicate rows in Customers DataFrame:\")\n",
    "duplicates_customers = data_cus[data_cus.duplicated()]\n",
    "print(duplicates_customers)\n",
    "\n",
    "# Check for duplicates in orders dataset\n",
    "print(\"\\nDuplicate rows in Orders DataFrame:\")\n",
    "duplicates_orders = data_sal[data_sal.duplicated()]\n",
    "print(duplicates_orders)\n",
    "\n",
    "# Remove duplicates in customers dataset\n",
    "customers_df_cleaned = data_cus.drop_duplicates()\n",
    "\n",
    "# Remove duplicates in orders dataset\n",
    "orders_df_cleaned = data_sal.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7169cd",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "- Create a new column in the sales.csv data that reflects the total amount after applying a\n",
    "- 10% discount on the Amount column. Group the data by Product and calculate the total sales\n",
    "- for each product. Present the results in a well-structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce335b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Product  Total_Sales\n",
      "2     Monitor     100800.0\n",
      "0  Headphones      79200.0\n",
      "4      Tablet      57600.0\n",
      "3  Smartphone      36000.0\n",
      "1      Laptop      14400.0\n"
     ]
    }
   ],
   "source": [
    "# Add a new column for the discounted total\n",
    "data_sal[\"Discounted_Amount\"] = data_sal[\"Amount\"] * 0.9\n",
    "\n",
    "# Group by Product and calculate total sales\n",
    "total_sales_by_product = data_sal.groupby(\"Product\")[\"Discounted_Amount\"].sum().reset_index()\n",
    "# Rename columns for clarity\n",
    "total_sales_by_product.rename(columns={\"Discounted_Amount\": \"Total_Sales\"}, inplace=True)\n",
    "# Sort by Total Sales\n",
    "total_sales_by_product = total_sales_by_product.sort_values(by=\"Total_Sales\", ascending=False)\n",
    "# Display the final DataFrame\n",
    "print(total_sales_by_product)\n",
    "\n",
    "\n",
    "# # Save the results to a new CSV file\n",
    "# total_sales_by_product.to_csv(\"total_sales_by_product.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c544d68",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "- Filter the data in the customers.csv file to retain only those customers whose age falls in the\n",
    "- range of 25 to 35. Save the filtered data in a new structure and analyze how many customers\n",
    "- belong to each city within this age range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2f009b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers in each city (age 25-35):\n",
      "          City  Customer_Count\n",
      "0      Chicago               7\n",
      "1      Houston              11\n",
      "2  Los Angeles               7\n",
      "3     New York               7\n",
      "4      Phoenix               8\n"
     ]
    }
   ],
   "source": [
    "# Filter customers whose age falls between 25 and 35\n",
    "filtered_customers = data_cus[(data_cus[\"Age\"] >= 25) & (data_cus[\"Age\"] <= 35)]\n",
    "\n",
    "# Group by City and count the number of customers\n",
    "customers_per_city = filtered_customers.groupby(\"City\")[\"CustomerID\"].count().reset_index()\n",
    "# Rename columns for clarity\n",
    "customers_per_city.rename(columns={\"CustomerID\": \"Customer_Count\"}, inplace=True)\n",
    "\n",
    "# # Save the filtered data to a new CSV file\n",
    "# filtered_customers.to_csv(\"filtered_customers_25_to_35.csv\", index=False)\n",
    "\n",
    "# Display the number of customers in each city within the age range\n",
    "print(\"Number of customers in each city (age 25-35):\")\n",
    "print(customers_per_city)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ac839",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "- Merge the customers.csv and sales.csv datasets on CustomerID. From the merged dataset:\n",
    "- Identify the city that generated the highest total sales.\n",
    "- Find the product with the most units sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53fdd3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City with the highest total sales:\n",
      "City      Phoenix\n",
      "Amount     112000\n",
      "Name: 4, dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Column not found: Quantity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(top_city)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Group by Product and calculate total units sold\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m product_sales \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProduct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuantity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Find the product with the most units sold\u001b[39;00m\n\u001b[0;32m     16\u001b[0m top_product \u001b[38;5;241m=\u001b[39m product_sales\u001b[38;5;241m.\u001b[39mloc[product_sales[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39midxmax()]\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1950\u001b[0m     )\n\u001b[1;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: Quantity'"
     ]
    }
   ],
   "source": [
    "# Merge customers and sales datasets\n",
    "merged_df = pd.merge(data_cus, data_sal, on=\"CustomerID\", how=\"inner\")\n",
    "\n",
    "# Group by City and calculate total sales\n",
    "city_sales = merged_df.groupby(\"City\")[\"Amount\"].sum().reset_index()\n",
    "\n",
    "# Find the city with the highest total sales\n",
    "top_city = city_sales.loc[city_sales[\"Amount\"].idxmax()]\n",
    "print(\"City with the highest total sales:\")\n",
    "print(top_city)\n",
    "\n",
    "# Group by Product and calculate total units sold\n",
    "product_sales = merged_df.groupby(\"Product\")[\"Quantity\"].sum().reset_index()\n",
    "\n",
    "# Find the product with the most units sold\n",
    "top_product = product_sales.loc[product_sales[\"Quantity\"].idxmax()]\n",
    "print(\"\\nProduct with the most units sold:\")\n",
    "print(top_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae18cf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
